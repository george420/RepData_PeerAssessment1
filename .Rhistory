unlink("testdir2", recursive = TRUE)
setwd("..")
getwd()
setwd(old.dir)
unlink("testdir")
unlink("testdir", recursive = TRUE)
1 : 20
pi : 10
15 : 1
?':'
seq(1, 20)
seq(0, 10, by = 0.5)
seq(5, 10, length = 30)
my_seq <- seq(5, 10, length = 30)
length(my_seq)
1 : length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "John")
my_name
paste(my_name, sep = " ")
paste(my_name, collapse  = " ")
paste("Hello", "world!", sep = " ")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
swirl()
library(swirl)
swirl()
x <- c(44, NA, 5, NA)
3*X
3*x
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf - Inf
x
x[1 : 10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[c(3, 5, 7)]
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
args(vect)
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identify(vect, vect2)
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
system.time(1)
mytime <- system.time(1)
names(mytime)
mytime$user.child
mytime["user.child"]
?dnorm
？sample
？sample()
?sample
sample(1 : 10, replace = TRUE)
sample(1 : 10, replace = TRUE)
sample(1 : 10, size = 20, replace = TRUE)
rep(0 : 1, each = 5)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(2)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
?quantile
getwd()
library("xlsx")
gasdata <- read.xlsx("gas.xlsx", sheetIndex = 1, rowIndex = 18 : 23, colIndex = 7 : 15, header = TRUE)
sum(gasdat$Zip*gasdat$Ext,na.rm=T)
sum(gasdate$Zip*gasdate$Ext,na.rm=T)
sum(gasdata$Zip*gasdata$Ext,na.rm=T)
fielUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile = "./GettingandCleaningData/restaurant.xlsx", method = "curl")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile = "./GettingandCleaningData/restaurant.xlsx", method = "curl")
library(XML)
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
xpathSApply(rootNode, "//name", xmlValue)
xpathSApply(rootNode, "//zip", xmlValue)
zipcode <- xpathSApply(rootNode, "//zipcode", xmlValue)
xmlSApply(rootNode, xmlValue)
xpathSApply(rootNode, "//zipcode[@zipcode='21231']", xmlValue)
zipcode <- as.numeric(zipcode)
zip <- zipcode[zipcode == 21231]
good <- zipcode == 21231
zip <- zipcode[good]
zip <- zipcode[(zipcode == 21231)]
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile = "./GettingandCleaningData/survey.csv", method = "curl")
??fread
library(data.table)
?fread
mydata <- fread("./GettingandCleaningData/survey.csv")
View(mydata)
DT <- mydata
loop <- 1000
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
time1 <- system.time(tapply(DT$pwgtp15,DT$SEX,mean))$user.self
system.time(tapply(DT$pwgtp15,DT$SEX,mean))[user.self]
system.time(tapply(DT$pwgtp15,DT$SEX,mean))["user.self"]
count <- 0
time1 <- while(count < loop) {
system.time(tapply(DT$pwgtp15,DT$SEX,mean))["user.self"]
count <- count + 1
}
time1
tapply(DT$pwgtp15,DT$SEX,mean)
sapply(split(DT$pwgtp15,DT$SEX),mean)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
rowMeans(DT)[DT$SEX==1]
rowMeans(DT)[DT$SEX==2]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
DT[,mean(pwgtp15),by=SEX]
mean(DT$pwgtp15,by=DT$SEX)
mean(DT$pwgtp15,by=DT$SEX)
time1 <- replicate(loop, system.time(tapply(DT$pwgtp15,DT$SEX,mean))["user.self"])
time2 <- replicate(loop, system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))["user.self"])
time4 <- replicate(loop, system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))["user.self"])
time5 <- replicate(loop, system.time(DT[,mean(pwgtp15),by=SEX])["user.self"])
time4 <- replicate(loop, system.time(mean(DT[DT$SEX==1,]$pwgtp15))["user.self"] + system.time(mean(DT[DT$SEX==2,]$pwgtp15))["user.self"])
ctime1 <- cumsum(time1)/seq_along(time1)
ctime2 <- cumsum(time2)/seq_along(time2)
ctime4 <- cumsum(time1)/seq_along(time4)
ctime5 <- cumsum(time1)/seq_along(time5)
plot(ctime1)
plot(ctime1, type = "l")
plot(ctime2, type = "l")
plot(ctime1, type = "l")
lines(ctime2)
lines(ctime3)
lines(ctime4)
lines(ctime5)
lines(ctime5)
plot(ctime2, type = "l")
plot(ctime1, type = "l")
?plot
top_Y <- max(ctime1, ctime2, ctime4, ctime5)
low_Y <- min(ctime1, ctime2, ctime4, ctime5)
plot(ctime1, type = "l", col = "red", ylim = c(low_Y, top_Y))
lines(ctime2, col = "blue")
lines(ctime4, col = "green")
lines(ctime5, col = "black")
?par
2075259*9*8
2075259*9*8/2^20
q
getwd()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "351e36b39cecc82325b1",
secret = "aaec8ca38c1a40c85cb4a55e1323888464234d29")
github_token <- oauth2.0_token(oauth_endpoint("github"), myapp)
?oauth2.0_token
github_token <- oauth2.0_token(oauth_endpoint("github"), myapp, cache = FALSE)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
str(req)
class(req)
json1 <- content(req)
json2 <- jsonlite::fromJSON(toJSON(json1))
?tojson
library(jsonlite)
json2 <- jsonlite::fromJSON(toJSON(json1))
str(json2)
class(json2)
names(json2)
head(json2)
create_time <- json2[, "created_at"]
names(json2)
created <- json2[, list("git_refs_url", "created_at")]
created <- json2[, c("git_refs_url", "created_at")]
View(created)
??match
x <- created$git_refs_url %nin% "datasharing"
?match
x <- match("datasharing", created$git_refs_url)
??match
x <- pmatch("datasharing", created$git_refs_url)
??is.element
"datasharing" %in% created$git_refs_url
?grep
??agrep
x <- agrep("datasharing", created$git_refs_url)
# 1. Find OAuth settings for github:
# Access the API to get information on your instructors repositories (hint: this is the url you want "https://api.github.com/users/jtleek/repos").
# Use this data to find the time that the datasharing repo was created. What time was it created?
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("github",
key = "351e36b39cecc82325b1",
secret = "aaec8ca38c1a40c85cb4a55e1323888464234d29")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
# 5. Converting the json object
json1 <- content(req)
json2 <- jsonlite::fromJSON(toJSON(json1))
repo_created <- json2[, c("git_refs_url", "created_at")]
time_created <- json2[agrep("datasharing", repo_created$git_refs_url), "created_at"]
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    https://github.com/settings/applications. Use any URL for the homepage URL
source('~/Documents/Coursera/DataScience/get_created_time_of_repo.R', echo=TRUE)
?readLines
?readLine
?readline
?readLines
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con, n = 10L)
htmlCode
htmlCode <- readLines(con)
close(con)
nchar(htmlCode[c(10, 20, 30, 100)])
?read.fwf
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
fileDownload <- download.file(fileUrl, destfile = "file1.for", method = "curl")
?download.file
doc <- read.fwf("file1.for", widths = c(9, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4), skip = 4)
View(doc)
doc <- read.fwf("file1.for", widths = c(10, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4), skip = 4)
doc <- read.fwf("file1.for", widths = c(10, 9, 4, 9, 4, 9, 4, 9, 4), skip = 4)
sum(doc$V9)
sum(doc$V4)
library(ggplot2)
str(mpg)
?qplot
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, geom = "point")
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))
qplot(drv, hwy, geom = "boxplot")
qplot(drv, hwy, data = mpg, geom = "boxplot")
?aes
?facet_wrap
?geom_smooth
??se
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?xyplot
str(BodyWeight)
?axis
?lpoints
?xyplot
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
lattice
?lattice
?trellis.par.set
?par
?splom
?print.trellis
?"ggplot2"
??"ggplot2"
library(datasets)
data("airquality")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
View(airquality)
str(airquality)
airquality <- transform(airquality, Month = factor(Month))
str(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
?qplot
?xyplot
xyplot()
xyplot
g <- xyplot(airquality$Ozone, airquality$Wind)
g <- xyplot(Ozone~Wind, airquality)
class(g)
?transform
?xtable
??xtable
install.packages("xtable")
setwd("./ReproducibleResearch/PeerAssessment1")
setwd("./ReproducibleResearch/RepData_PeerAssessment1")
getwd()
setwd("~/Documents/Coursera/DataScience/ReproducibleResearch/RepData_PeerAssessment1")
doc <- unzip("activity.zip")
activity <- read.csv(doc)
View(activity)
str(activity)
?aggregate
x <- aggregate(activity, by = activity$date, sum)
x <- aggregate(activity, by = level(activity$date), sum)
x <- aggregate(activity, by = levels(activity$date), sum)
by = levels(activity$date)
x <- tapply(activity$steps, activity$date, sum)
x
class(x)
levels(x)
factor(x)
dim(x)
hist(x)
x <- tapply(activity$steps, activity$date, sum, simplify = F)
str(x)
dimnames(x)
class(dimnames(x))
?rep
y <- as.Date(activity$date)
z <- rep(y, x)
as.list(x)
activity_new <- activity[!is.na(activity$steps), ]
day <- as.Date(levels(activity_new$date))
steps <- tapply(activity_new$steps, activity_new$date, sum)
day_steps <- rep(day, steps)
View(activity_new)
day <- as.Date(unique(activity_new$date))
steps <- tapply(activity_new$steps, activity_new$date, sum)
steps <- tapply(activity$steps, activity$date, sum, na.rm = T)
rep(1, 0)
rep(1, 1)
rep(1, 2)
rep(1, 0)
day <- as.Date(levels(activity$date))
steps <- tapply(activity$steps, activity$date, sum, na.rm = T)
day_steps <- rep(day, steps)
str(day_steps)
hist(day_steps)
x <- aggregate(steps ~ date, activity_new, sum)
View(x)
hist(x$steps)
day_steps <- tapply(steps ~ date, activity_new, sum)
hist(day_steps)
?aggregate
day_steps <- aggregate(steps ~ date, activity, sum, na.action = na.omit)
hist(day_steps)
View(day_steps)
interval_steps <- aggregate(steps ~ interval, activity, mean, na.action = na.omit)
View(interval_steps)
with(interval_step, plot(interval, steps))
?match
?aggregate
View(day_steps)
View(interval_steps)
2355/5
max(interval_steps$interval)
interval_steps <- aggregate(steps ~ interval, activity, mean)
View(interval_steps)
date_steps <- aggregate(steps ~ date, activity, sum)
View(day_steps)
doc <- unzip("activity.zip")
activity <- read.csv(doc)
activity_new <- activity[!is.na(activity$steps), ]
date_steps <- aggregate(steps ~ date, activity_new, sum)
hist(date_steps$steps, xlab = "Total number of steps taken each day", main = "Histogram of the total number of steps taken each day")
View(date_steps)
View(date_steps)
View(activity_new)
interval_steps <- aggregate(steps ~ interval, activity_new, mean)
with(interval_steps, plot(interval, steps, type = "l", xlab = "Interval", ylab = "Average number of steps"))
View(interval_steps)
288*5
View(interval_steps)
View(activity_new)
nrow(activity_new)
activity_new <- na.omit(activity)
View(activity_new)
interval_steps <- aggregate(steps ~ interval, activity_new, mean)
View(interval_steps)
View(activity)
doc <- unzip("activity.zip")
activity <- read.csv(doc)
date_steps <- aggregate(steps ~ date, activity, sum)
mean_steps <- as.integer(mean(date_steps$steps))
median_steps <- median(date_steps$steps)
interval_steps <- aggregate(steps ~ interval, activity, mean)
with(interval_steps, plot(interval, steps, type = "l", xlab = "Interval", ylab = "Average number of steps"))
View(interval_steps)
for (i in 1 : nrow(activity)) {
if (is.na(activity$steps[i])) {
interval_val <- activity$interval[i]
row_id <- which(interval_steps$interval == interval_val)
activity$steps[i] <- interval_steps$interval[row_id]
}
}
View(activity)
date_steps_imputed <- aggregate(steps ~ date, activity, sum)
hist(date_steps_imputed$steps)
View(date_steps_imputed)
for (i in 1 : nrow(activity)) {
if (is.na(activity$steps[i])) {
interval_val <- activity$interval[i]
row_id <- which(interval_steps$interval == interval_val)
activity$steps[i] <- interval_steps$steps[row_id]
}
}
View(date_steps_imputed)
for (i in 1 : nrow(activity)) {
if (is.na(activity$steps[i])) {
interval_val <- activity$interval[i]
row_id <- which(interval_steps$interval == interval_val)
activity$steps[i] <- interval_steps$steps[row_id]
}
}
date_steps_imputed <- aggregate(steps ~ date, activity, sum)
hist(date_steps_imputed$steps, main = "Histogram of the total number of steps taken each day", xlab = "Total number of steps taken each day")
View(activity)
doc <- unzip("activity.zip")
activity <- read.csv(doc)
date_steps <- aggregate(steps ~ date, activity, sum)
interval_steps <- aggregate(steps ~ interval, activity, mean)
for (i in 1 : nrow(activity)) {
if (is.na(activity$steps[i])) {
interval_val <- activity$interval[i]
row_id <- which(interval_steps$interval == interval_val)
activity$steps[i] <- interval_steps$steps[row_id]
}
}
date_steps_imputed <- aggregate(steps ~ date, activity, sum)
View(date_steps_imputed)
View(activity)
View(date_steps_imputed)
mean_steps_imputed <- as.integer(mean(date_steps_imputed$steps))
median_steps_imputed <- as.integer(median(date_steps_imputed$steps))
?median
median(c(2 1 3))
median(c(2, 1, 3))
activity$weekdays <- weekdays(activity$date)
as.Date(activity$date)
activity$date <- as.Date(activity$date)
activity$weekdays <- weekdays(activity$date)
View(activity)
?weekdays
library(sqldf)
?select
activity$day <- weekdays(activity$date)
activity$day[( activity$day == "Saturday" | "Sunday" )] <- "weekend"
activity$day == "Saturday" | "Sunday"
activity$day == ( "Saturday" | "Sunday" )
activity$day == ( "Saturday" || "Sunday" )
activity$weekday == ( "Saturday" || "Sunday" )
activity$weekdays <- weekdays(activity$date)
activity$weekdays[( activity$day == "Saturday" | "Sunday" )] <- "weekend"
activity$weekdays <- weekdays(activity$date)
activity$weekdays[( activity$day == "Saturday" )] <- "weekend"
activity$weekdays <- weekdays(activity$date)
activity$weekdays[( activity$day == "Saturday" || activity$day == "Sunday")] <- "weekend"
activity$day == "Saturday" || activity$day == "Sunday"
?if
